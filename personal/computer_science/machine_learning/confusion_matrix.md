---
reviewed_on: "2025-02-15"
---

A confusion matrix is a table used to evaluate the performance of a **classification** model. It provides a detailed breakdown of the model's predictions compared to the actual outcomes, helping to identify where the model is making errors. The matrix is particularly useful for binary and multi-class classification problems.

|                   |    **actual yes**    |    **actual no**     |
|:-----------------:|:--------------------:|:--------------------:|
| **predicted yes** | true positive (TP).  | false positive (FP). |
| **predicted no**  | false negative (FN). | true negative (TN).  |
